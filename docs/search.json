[
  {
    "objectID": "aula1.html#exemplo-1",
    "href": "aula1.html#exemplo-1",
    "title": "Aula 1",
    "section": "Exemplo 1",
    "text": "Exemplo 1\n\n\n\n# Dados daqui: https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)\n\n# Ler dados\n\ncol_names <- janitor::make_clean_names(c(\"Clump Thickness\",\n\"Uniformity of Cell Size\",\n\"Uniformity of Cell Shape\",\n\"Marginal Adhesion\",\n\"Single Epithelial Cell Size\",\n\"Bare Nuclei\",\n\"Bland Chromatin\",\n\"Normal Nucleoli\",\n\"Mitoses\",\n\"Class\"\n))\n\ncol_names <- c(\n  \"id\", \"diag\",\n  paste0(col_names, \"_mean\"),\n  paste0(col_names, \"_se\"),\n  paste0(col_names, \"_worst\")\n)\n\ndata <- readr::read_csv(\"dados/wdbc.data\",\n                col_names = col_names, na = \"?\")\n\n# Definir o modelo:\n\nlibrary(keras)\nlibrary(tensorflow)\n\ninput <- layer_input(shape = shape(30))\noutput <- input %>%\n  layer_dense(units = 5, activation = \"relu\") %>%\n  layer_dense(units = 1)\nmodel <- keras_model(input, output)\n\n\nmodel %>% compile(\n  loss = loss_binary_crossentropy(from_logits = TRUE),\n  optimizer = optimizer_adam(),\n  metrics = \"accuracy\"\n)\n\n# Ajustar o modelo\n\nmodel %>%\n  fit(\n    x = as.matrix(data[-c(1,2)]),\n    y = as.numeric(data$diag == \"M\"),\n    batch_size = 10,\n    epochs = 100,\n    validation_split = 0.2\n  )\n\nget_weights(model)\npredict(model, as.matrix(data[-c(1,2)]))"
  },
  {
    "objectID": "aula1.html#exemplo-2",
    "href": "aula1.html#exemplo-2",
    "title": "Aula 1",
    "section": "Exemplo 2",
    "text": "Exemplo 2\n\nArquivo p/ rodar\n\n\n\nlibrary(tfruns)\n\nruns <- list()\n\nfor (i in 1:5) {\n  runs[[i]] <- tuning_run(\n    \"tune.R\",\n    flags = list(\n      hidden_layer_1 = c(5, 10, 15),\n      hidden_layer_2 = c(0, 5, 10, 15)\n    ),\n    confirm = FALSE\n  )\n}\n\nlibrary(tidyverse)\n\nruns %>%\n  bind_rows() %>%\n  group_by(flag_hidden_layer_1, flag_hidden_layer_2) %>%\n  summarise(\n    mean = mean(metric_val_accuracy),\n    sd = sd(metric_val_accuracy)\n  ) %>%\n  arrange(desc(mean))\n\n\n\n\n\nArquivo espec\n\n\n\n# Ler dados\n\ncol_names <- janitor::make_clean_names(c(\"Clump Thickness\",\n                                         \"Uniformity of Cell Size\",\n                                         \"Uniformity of Cell Shape\",\n                                         \"Marginal Adhesion\",\n                                         \"Single Epithelial Cell Size\",\n                                         \"Bare Nuclei\",\n                                         \"Bland Chromatin\",\n                                         \"Normal Nucleoli\",\n                                         \"Mitoses\",\n                                         \"Class\"\n))\n\ncol_names <- c(\n  \"id\", \"diag\",\n  paste0(col_names, \"_mean\"),\n  paste0(col_names, \"_se\"),\n  paste0(col_names, \"_worst\")\n)\n\ndata <- readr::read_csv(\"dados/wdbc.data\",\n                        col_names = col_names, na = \"?\")\n\n\n# VariÃ¡veis:\n\nlibrary(tfruns)\n\nFLAGS <- flags(\n  flag_integer('hidden_layer_1', 5, 'Size of the first hidden layer'),\n  flag_integer(\"hidden_layer_2\", 0, \"Size of the second hidden layer\")\n)\n\n# Definir o modelo:\n\nlibrary(keras)\nlibrary(tensorflow)\n\ninput <- layer_input(shape = shape(30))\noutput <- input %>%\n  layer_dense(units = FLAGS$hidden_layer_1, activation = \"relu\")\n\nif (FLAGS$hidden_layer_2 > 0) {\n  output <- output %>%\n    layer_dense(units = FLAGS$hidden_layer_2, activation = \"relu\")\n}\n\noutput <- output %>%\n  layer_dense(units = 1)\n\nmodel <- keras_model(input, output)\n\nmodel %>% compile(\n  loss = loss_binary_crossentropy(from_logits = TRUE),\n  optimizer = optimizer_adam(),\n  metrics = \"accuracy\"\n)\n\n# Ajustar o modelo\n\nmodel %>%\n  fit(\n    x = as.matrix(data[-c(1,2)]),\n    y = as.numeric(data$diag == \"M\"),\n    batch_size = 10,\n    epochs = 100,\n    validation_split = 0.2,\n    callbacks = list(\n      callback_early_stopping(patience = 5)\n    )\n  )"
  },
  {
    "objectID": "aula1.html#exemplo-3",
    "href": "aula1.html#exemplo-3",
    "title": "Aula 1",
    "section": "Exemplo 3",
    "text": "Exemplo 3\nBaixar os dados daqui\n\n\n\n# Carregando os dados\n\nlibrary(keras)\nlibrary(tensorflow)\n\narquivos <- fs::dir_ls(\"dados/images/\", glob = \"*.jpg\")\nclasses <- arquivos %>%\n  fs::path_file() %>%\n  stringr::str_extract(\"(.*)_\") %>%\n  stringr::str_sub(end = -2)\n\nall_class <- unique(classes)\nclasses_int <- match(classes, all_class) - 1L\n\nlibrary(tfdatasets)\n\nmake_dataset <- function(arquivos, classes_int) {\n  tensor_slices_dataset(list(arq = arquivos, classe = classes_int)) %>%\n    dataset_map(function(x) {\n      img <- x$arq %>%\n        tf$io$read_file() %>%\n        tf$image$decode_jpeg(channels = 3) %>%\n        tf$image$resize(c(32L, 32L)) %>%\n        tf$image$convert_image_dtype(tf$float32)\n      list(img, x$classe)\n    }, num_parallel_calls = tf$data$AUTOTUNE) %>%\n    dataset_batch(32) %>%\n    dataset_prefetch(tf$data$AUTOTUNE)\n}\n\n\nid_train <- sample.int(length(arquivos), 0.8*length(arquivos))\n\ntrain_dataset <- make_dataset(\n  arquivos = arquivos[id_train],\n  classes_int = classes_int[id_train]\n)\n\nvalid_dataset <- make_dataset(\n  arquivos = arquivos[-id_train],\n  classes_int = classes_int[-id_train]\n)\n\ncoro::collect(train_dataset, 2)[[1]][[1]][4,,,] %>%\n  as.array() %>%\n  as.raster(max = 255) %>%\n  plot()\n\n# Construir o modelo\n\ninput <- layer_input(shape = shape(32, 32, 3))\noutput <- input %>%\n  layer_rescaling(scale = 1/255) %>%\n\n  layer_conv_2d(\n    filter = 16, kernel_size = c(3,3), padding = \"same\",\n    input_shape = c(32, 32, 3)\n  ) %>%\n  layer_activation_leaky_relu(0.1) %>%\n\n  # Second hidden layer\n  layer_conv_2d(filter = 32, kernel_size = c(3,3)) %>%\n  layer_activation_leaky_relu(0.1) %>%\n\n  # Use max pooling\n  layer_max_pooling_2d(pool_size = c(2,2)) %>%\n  layer_dropout(0.25) %>%\n\n  # 2 additional hidden 2D convolutional layers\n  layer_conv_2d(filter = 32, kernel_size = c(3,3), padding = \"same\") %>%\n  layer_activation_leaky_relu(0.1) %>%\n  layer_conv_2d(filter = 64, kernel_size = c(3,3)) %>%\n  layer_activation_leaky_relu(0.1) %>%\n\n  # Use max pooling once more\n  layer_max_pooling_2d(pool_size = c(2,2)) %>%\n  layer_dropout(0.25) %>%\n\n  # Flatten max filtered output into feature vector\n  # and feed into dense layer\n  layer_flatten() %>%\n  layer_dense(256) %>%\n  layer_activation_leaky_relu(0.1) %>%\n  layer_dropout(0.5) %>%\n\n  # Outputs from dense layer are projected onto 10 unit output layer\n  layer_dense(37)\n\nmodel <- keras_model(input, output)\nmodel %>%\n  compile(\n    loss = loss_sparse_categorical_crossentropy(from_logits = TRUE),\n    optimizer = \"adam\",\n    metrics = \"accuracy\"\n  )\n\n\nmodel %>%\n  fit(\n    train_dataset,\n    validation_data = valid_dataset\n  )"
  },
  {
    "objectID": "aula1.html#exemplo-4",
    "href": "aula1.html#exemplo-4",
    "title": "Aula 1",
    "section": "Exemplo 4",
    "text": "Exemplo 4\n\n\n\n# Carregando os dados\n\nlibrary(keras)\nlibrary(tensorflow)\nlibrary(tfdatasets)\n\narquivos <- fs::dir_ls(\"dados/images/\", glob = \"*.jpg\")\ntrimaps <- fs::path(\n  \"dados/annotations/trimaps/\",\n  fs::path_file(arquivos)\n)\nfs::path_ext(trimaps) <- \"png\"\n\nimg_size <- c(32L, 32L)\n\nread_trimap <- function(trimap) {\n  tr <- trimap %>%\n    tf$io$read_file() %>%\n    tf$image$decode_png() %>%\n    tf$image$resize(img_size)\n  tr - 1L\n}\n\ndisplay_target <- function(target_array) {\n  normalized_array <- (target_array) * 127\n  normalized_array <- tf$image$grayscale_to_rgb(as_tensor(normalized_array))\n  normalized_array <- as.raster(as.array(normalized_array), max = 255)\n  plot(normalized_array)\n}\n\ndisplay_target(as.array(read_trimap(trimaps[1])))\n\nread_img <- function(arq) {\n  arq %>%\n    tf$io$read_file() %>%\n    tf$image$decode_jpeg(channels = 3) %>%\n    tf$image$resize(img_size) %>%\n    tf$image$convert_image_dtype(tf$float32)\n}\n\nread_img(arquivos[2]) %>%\n  as.array() %>%\n  as.raster(max = 255) %>%\n  plot()\n\n\nmake_dataset <- function(arquivos, trimaps) {\n  list(arquivos = arquivos, trimaps = trimaps) %>%\n    tensor_slices_dataset() %>%\n    dataset_map(function(x) {\n      list(\n        read_img(x$arquivos),\n        read_trimap(x$trimaps)\n      )\n    }, num_parallel_calls = tf$data$AUTOTUNE) %>%\n    dataset_batch(32) %>%\n    dataset_prefetch(tf$data$AUTOTUNE)\n}\n\nid_train <- sample.int(length(arquivos), 0.8*length(arquivos))\n\ntrain_dataset <- make_dataset(\n  arquivos = arquivos[id_train],\n  trimaps = trimaps[id_train]\n)\n\nvalid_dataset <- make_dataset(\n  arquivos = arquivos[-id_train],\n  trimaps = trimaps[-id_train]\n)\n\ncoro::collect(train_dataset, 2)[[1]][[1]][4,,,] %>%\n  as.array() %>%\n  as.raster(max = 255) %>%\n  plot()\n\n# Construir o modelo\n\nget_model <- function(img_size, num_classes) {\n  input <- layer_input(shape = c(img_size, 3))\n  output <- input %>%\n    layer_rescaling(scale = 1/255) %>%\n    layer_conv_2d(filters = 64, kernel_size = 3, strides = 2, activation = \"relu\",\n                  padding = \"same\") %>%\n    layer_conv_2d(filters = 64, kernel_size = 3, activation = \"relu\",\n                  padding = \"same\") %>%\n    layer_conv_2d(filters = 128, kernel_size = 3, strides = 2, activation = \"relu\",\n                  padding = \"same\") %>%\n    layer_conv_2d(filters = 128, kernel_size = 3, activation = \"relu\",\n                  padding = \"same\") %>%\n    layer_conv_2d(filters = 256, kernel_size = 3, strides = 2, activation = \"relu\",\n                  padding = \"same\") %>%\n    layer_conv_2d(filters = 256, kernel_size = 3, activation = \"relu\",\n                  padding = \"same\") %>%\n\n    layer_conv_2d_transpose(filters = 256, kernel_size = 3, activation = \"relu\",\n                            padding = \"same\") %>%\n    layer_conv_2d_transpose(filters = 256, kernel_size = 3, activation = \"relu\",\n                            padding = \"same\", strides = 2) %>%\n    layer_conv_2d_transpose(filters = 128, kernel_size = 3, activation = \"relu\",\n                            padding = \"same\") %>%\n    layer_conv_2d_transpose(filters = 128, kernel_size = 3, activation = \"relu\",\n                            padding = \"same\", strides = 2) %>%\n    layer_conv_2d_transpose(filters = 64, kernel_size = 3, activation = \"relu\",\n                            padding = \"same\") %>%\n    layer_conv_2d_transpose(filters = 64, kernel_size = 3, activation = \"relu\",\n                            padding = \"same\", strides = 2) %>%\n\n    layer_conv_2d(num_classes, 3, activation=\"softmax\", padding=\"same\")\n\n\n  keras_model(input, output)\n}\n\nmodel <- get_model(img_size=img_size, num_classes=3)\nmodel\n\nmodel %>%\n  compile(\n    loss = \"sparse_categorical_crossentropy\",\n    optimizer = \"rmsprop\"\n  )\n\n\nmodel %>%\n  fit(\n    train_dataset,\n    validation_data = valid_dataset\n  )\n\nbatch <- coro::collect(valid_dataset, 1)[[1]]\npreds <- predict(model, batch[[1]])\n\ndisplay_mask <- function(pred) {\n  mask <- tf$argmax(pred, axis=-1L) * 127\n  mask[1,,] %>%\n    tf$expand_dims(-1L) %>%\n    tf$image$grayscale_to_rgb() %>%\n    as.array() %>%\n    as.raster(max = 255) %>%\n    plot()\n}\n\nplot(as.raster(as.array(batch[[1]][1,,,]), max = 255))\ndisplay_mask(preds)\ndisplay_target(batch[[2]][1,,,])"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SINAPE",
    "section": "",
    "text": "Site com conteÃºdos do curso de Deep Learning ministrado no SINAPE 2022."
  },
  {
    "objectID": "aula2.html#exemplo-1",
    "href": "aula2.html#exemplo-1",
    "title": "Aula 2",
    "section": "Exemplo 1",
    "text": "Exemplo 1\n\n\n\nlibrary(keras)\nlibrary(tensorflow)\nlibrary(tfdatasets)\nlibrary(raster)\n\n# Carregando dados\n\nmnist <- dataset_mnist()\n\nmake_generator <- function() {\n  input <- layer_input(shape = shape(100))\n\n  output <- input %>%\n    layer_dense(7*7*256, use_bias = FALSE) %>%\n    layer_batch_normalization() %>%\n    layer_activation_leaky_relu() %>%\n\n    layer_reshape(c(7, 7, 256)) %>%\n\n    layer_conv_2d_transpose(128, c(5,5), strides = c(1,1), padding = \"same\",\n                            use_bias = FALSE) %>%\n    layer_batch_normalization() %>%\n    layer_activation_leaky_relu() %>%\n\n    layer_conv_2d_transpose(64, c(5,5), strides = c(2,2), padding = \"same\",\n                            use_bias = FALSE) %>%\n    layer_batch_normalization() %>%\n    layer_activation_leaky_relu() %>%\n\n    layer_conv_2d_transpose(1, c(5,5), strides = c(2,2), padding = \"same\",\n                            use_bias = FALSE, activation = \"tanh\")\n\n  keras_model(input, output)\n}\n\ngen <- make_generator()\n\ngenerate_image <- function(generator) {\n  noise <- rnorm(100)\n  generated_image <- predict(generator, matrix(noise, nrow = 1))\n  plot(raster(generated_image[1,,,1]))\n  generated_image\n}\n\ngenerate_image(gen)\n\nmake_discriminator <- function() {\n  input <- layer_input(shape = shape(28, 28, 1))\n  output <- input %>%\n    layer_conv_2d(64, c(5,5), strides = c(2,2), padding = \"same\") %>%\n    layer_activation_leaky_relu() %>%\n    layer_dropout(0.3) %>%\n\n    layer_conv_2d(128, c(5,5), strides = c(2,2), padding = \"same\") %>%\n    layer_activation_leaky_relu() %>%\n    layer_dropout(0.3) %>%\n\n    layer_flatten() %>%\n    layer_dense(1)\n\n  keras_model(input, output)\n}\n\ndisc <- make_discriminator()\ndecision <- disc(generate_image(gen))\ntf$sigmoid(decision)\n\ncross_entropy <- loss_binary_crossentropy(from_logits = TRUE)\n\ndiscriminator_loss <- function(real_output, fake_output) {\n  real_loss <- cross_entropy(tf$ones_like(real_output), real_output)\n  fake_loss <- cross_entropy(tf$zeros_like(fake_output), fake_output)\n  total_loss <- real_loss + fake_loss\n  total_loss\n}\n\ngenerator_loss <- function(fake_output) {\n  cross_entropy(tf$ones_like(fake_output), fake_output)\n}\n\nDCGAN <- new_model_class(\n  \"DCGAN\",\n  initialize = function() {\n    super()$`__init__`()\n    self$generator <- make_generator()\n    self$discriminator <- make_discriminator()\n  },\n  compile = function() {\n    super()$compile()\n    self$g_optimizer <- optimizer_adam(1e-4)\n    self$d_optimizer <- optimizer_adam(1e-4)\n\n    self$d_loss_metric <- tf$keras$metrics$Mean(name = \"d_loss\")\n    self$g_loss_metric <- tf$keras$metrics$Mean(name = \"g_loss\")\n  },\n  train_step = function(images) {\n    noise <- tf$random$normal(shape(256, 100))\n\n    with(tf$GradientTape() %as% tape, {\n      generated_images <- self$generator(noise, training=TRUE)\n      fake_output <- self$discriminator(generated_images, training=TRUE)\n      gen_loss <- generator_loss(fake_output)\n    })\n\n    grads <- tape$gradient(gen_loss, self$generator$trainable_variables)\n    self$g_optimizer$apply_gradients(\n      zip_lists(grads, self$generator$trainable_variables)\n    )\n\n    with(tf$GradientTape() %as% tape, {\n      generated_images <- self$generator(noise, training=TRUE)\n      fake_output <- self$discriminator(generated_images, training=TRUE)\n      real_output <- self$discriminator(images, training=TRUE)\n      disc_loss <- discriminator_loss(real_output, fake_output)\n    })\n\n    grads <-tape$gradient(disc_loss, self$discriminator$trainable_variables)\n    self$d_optimizer$apply_gradients(\n      zip_lists(grads, self$discriminator$trainable_variables)\n    )\n\n    self$d_loss_metric$update_state(disc_loss)\n    self$g_loss_metric$update_state(gen_loss)\n    list(\n      d_loss = self$d_loss_metric$result(),\n      g_loss = self$g_loss_metric$result()\n    )\n  }\n)\n\ndataset <- tensor_slices_dataset(mnist$train) %>%\n  dataset_map(function(x) {\n    (x$x/255 - 0.5)*2\n  }) %>%\n  dataset_shuffle(buffer_size = 10000) %>%\n  dataset_batch(256) %>%\n  dataset_prefetch()\n\nmodel <- DCGAN()\nmodel %>% compile()\nmodel %>% fit(dataset, epochs = 50)\n\ninvisible(generate_image(model$generator))"
  },
  {
    "objectID": "aula2.html#exemplo-2",
    "href": "aula2.html#exemplo-2",
    "title": "Aula 2",
    "section": "Exemplo 2",
    "text": "Exemplo 2\n\n\n\nlibrary(keras)\nlibrary(tensorflow)\nlibrary(tfdatasets)\nlibrary(raster)\n\n# Carregando dados\n\nmnist <- dataset_mnist()\n\nmake_generator <- function() {\n  input_noise <- layer_input(shape = shape(100))\n  input_class <- layer_input(shape = shape(), dtype = \"int64\")\n\n  latent_class <- input_class %>%\n    layer_embedding(input_dim = 10, output_dim = 100)\n\n  latent_noise <- input_noise %>%\n    layer_dense(units = 100, activation = \"relu\")\n\n  latent_input <- layer_concatenate(list(latent_noise, latent_class))\n\n  output <- latent_input %>%\n    layer_dense(7*7*256, use_bias = FALSE) %>%\n    layer_batch_normalization() %>%\n    layer_activation_leaky_relu() %>%\n\n    layer_reshape(c(7, 7, 256)) %>%\n\n    layer_conv_2d_transpose(128, c(5,5), strides = c(1,1), padding = \"same\",\n                            use_bias = FALSE) %>%\n    layer_batch_normalization() %>%\n    layer_activation_leaky_relu() %>%\n\n    layer_conv_2d_transpose(64, c(5,5), strides = c(2,2), padding = \"same\",\n                            use_bias = FALSE) %>%\n    layer_batch_normalization() %>%\n    layer_activation_leaky_relu() %>%\n\n    layer_conv_2d_transpose(1, c(5,5), strides = c(2,2), padding = \"same\",\n                            use_bias = FALSE, activation = \"tanh\")\n\n  keras_model(list(input_noise, input_class), output)\n}\n\ngen <- make_generator()\n\n\ngenerate_image <- function(generator, class) {\n  noise <- rnorm(100)\n  generated_image <- predict(generator, list(matrix(noise, nrow = 1), class))\n  plot(raster(generated_image[1,,,1]))\n  generated_image\n}\n\ngenerate_image(gen, 1L)\n\nmake_discriminator <- function() {\n  input <- layer_input(shape = shape(28, 28, 1))\n  vector <- input %>%\n    layer_conv_2d(64, c(5,5), strides = c(2,2), padding = \"same\") %>%\n    layer_activation_leaky_relu() %>%\n    layer_dropout(0.3) %>%\n\n    layer_conv_2d(128, c(5,5), strides = c(2,2), padding = \"same\") %>%\n    layer_activation_leaky_relu() %>%\n    layer_dropout(0.3) %>%\n\n    layer_flatten()\n\n\n  prob <- vector %>%\n    layer_dense(1)\n\n  class <- vector %>%\n    layer_dense(10)\n\n  keras_model(input, list(prob = prob, class = class))\n}\n\ndisc <- make_discriminator()\ndecision <- disc(generate_image(gen, 1))\ndecision\n\ncross_entropy <- loss_binary_crossentropy(from_logits = TRUE)\n\ndiscriminator_loss <- function(real_output, fake_output) {\n  real_loss <- cross_entropy(tf$ones_like(real_output), real_output)\n  fake_loss <- cross_entropy(tf$zeros_like(fake_output), fake_output)\n  total_loss <- real_loss + fake_loss\n  total_loss\n}\n\nclassification_loss <- function(target_class, predicted) {\n  loss_sparse_categorical_crossentropy(target_class, predicted, from_logits = TRUE)\n}\n\ngenerator_loss <- function(fake_output) {\n  cross_entropy(tf$ones_like(fake_output), fake_output)\n}\n\nACGAN <- new_model_class(\n  \"ACGAN\",\n  initialize = function() {\n    super()$`__init__`()\n    self$generator <- make_generator()\n    self$discriminator <- make_discriminator()\n  },\n  compile = function() {\n    super()$compile()\n    self$g_optimizer <- optimizer_adam(1e-4)\n    self$d_optimizer <- optimizer_adam(1e-4)\n\n    self$d_loss_metric <- tf$keras$metrics$Mean(name = \"d_loss\")\n    self$g_loss_metric <- tf$keras$metrics$Mean(name = \"g_loss\")\n  },\n  train_step = function(data) {\n    images <- data[[1]]\n    images_class <- data[[2]]\n\n    noise <- tf$random$normal(shape(256, 100))\n    class <- tf$random$uniform(shape(256), minval = 0L, maxval = 9L,  dtype = \"int64\")\n\n    with(tf$GradientTape() %as% tape, {\n      generated_images <- self$generator(list(noise, class), training=TRUE)\n      fake_output <- self$discriminator(generated_images, training=TRUE)\n      gen_loss <-\n        generator_loss(fake_output$prob) +\n        classification_loss(class, fake_output$class)\n    })\n\n    grads <- tape$gradient(gen_loss, self$generator$trainable_variables)\n    self$g_optimizer$apply_gradients(\n      zip_lists(grads, self$generator$trainable_variables)\n    )\n\n    with(tf$GradientTape() %as% tape, {\n      generated_images <- self$generator(list(noise, class), training=TRUE)\n      fake_output <- self$discriminator(generated_images, training=TRUE)\n      real_output <- self$discriminator(images, training=TRUE)\n      disc_loss <- discriminator_loss(real_output$prob, fake_output$prob) +\n        classification_loss(images_class, real_output$class)\n    })\n\n    grads <- tape$gradient(disc_loss, self$discriminator$trainable_variables)\n    self$d_optimizer$apply_gradients(\n      zip_lists(grads, self$discriminator$trainable_variables)\n    )\n\n    self$d_loss_metric$update_state(disc_loss)\n    self$g_loss_metric$update_state(gen_loss)\n    list(\n      d_loss = self$d_loss_metric$result(),\n      g_loss = self$g_loss_metric$result()\n    )\n  }\n)\n\ndataset <- tensor_slices_dataset(mnist$train) %>%\n  dataset_map(function(x) {\n    list(\n      (x$x/255 - 0.5)*2,\n      x$y\n    )\n  }) %>%\n  dataset_shuffle(buffer_size = 10000) %>%\n  dataset_batch(256) %>%\n  dataset_prefetch()\n\nmodel <- ACGAN()\nmodel %>% compile()\nmodel %>% fit(dataset, epochs = 50)\n\ninvisible(generate_image(model$generator, 6L))\n\nsave_model_tf(model, \"acgan\")\nsave_model_weights_tf(model, \"acgan-checkpoint\")"
  }
]